[
  {
    "id": "arima_time_series_model",
    "title": "时间序列ARIMA预测模型",
    "description": "基于自回归积分滑动平均（ARIMA）模型的单变量时间序列预测工具，支持自动参数调优与手动参数配置，适用于销量、库存、经济指标等短期至中期趋势预测。",
    "author": "Doubao-1.8",
    "version": "1.0",
    "trigger": "当用户需要对单变量时间序列数据进行预测时触发，场景包括但不限于月度销量预测、季度经济指标预测、库存需求预测等。",
    "output_format": "包含预测值序列、95%置信区间、模型训练评估指标（MAE、RMSE）的结构化字典结果。",
    "content": "---\nname: 时间序列ARIMA预测模型\ndescription: 基于自回归积分滑动平均（ARIMA）模型的单变量时间序列预测工具，支持自动参数调优与手动参数配置，适用于销量、库存、经济指标等短期至中期趋势预测。\nauthor: Doubao-1.8\nversion: 1.0\ntrigger: 当用户需要对单变量时间序列数据进行预测时触发，场景包括但不限于月度销量预测、季度经济指标预测、库存需求预测等。\noutput_format: 包含预测值序列、95%置信区间、模型训练评估指标（MAE、RMSE）的结构化字典结果。\n---\n\n## 工作流程\n1. **数据准备**：加载单变量时间序列数据，确保数据为带datetime类型索引的Pandas Series或DataFrame，处理缺失值（插值/删除）与异常值。\n2. **平稳性处理**：通过ADF检验判断序列平稳性，若不平稳则进行差分操作确定d值。\n3. **参数选择**：\n   - 手动模式：通过ACF/PACF图分析确定AR阶数p和MA阶数q；\n   - 自动模式：使用AutoARIMA算法自动搜索最优p、d、q组合。\n4. **模型训练**：利用选定参数训练ARIMA模型，完成参数估计与残差检验。\n5. **模型评估**：计算训练集的MAE、RMSE指标，验证残差是否为白噪声。\n6. **预测输出**：生成指定未来步数的预测值及置信区间，支持可视化展示。\n\n## 约束条件\n1. 仅支持单变量时间序列数据，输入需包含连续的时间索引（如日、月、季度）。\n2. 模型适用于短期至中期预测，建议预测步数不超过原始序列长度的20%。\n3. 若序列存在明显季节性趋势，建议使用SARIMA模型替代本工具。\n4. 输入数据缺失值占比需低于5%，否则需先完成缺失值处理。\n\n## 工具使用\n本技能的ARIMA模型实现代码位于`scripts/model.py`，提供`ARIMAPredictor`类，核心功能如下：\n- `__init__`：初始化模型，支持手动设置p、d、q参数或启用自动调优模式；\n- `fit`：输入时间序列数据完成模型训练，自动完成数据校验与参数优化（若开启自动调优）；\n- `forecast`：生成未来指定步数的预测结果，返回预测值、置信区间及评估指标；\n- `plot_forecast`：可视化原始序列与预测结果，包含置信区间阴影。",
    "tags": [
      {
        "id": "t1",
        "name": "数学建模"
      }
    ],
    "downloadCount": 0,
    "rating": 5.0,
    "publishDate": "2026-01-30",
    "icon": "Code",
    "color": "blue",
    "status": "approved",
    "user": {
      "id": "id",
      "name": "Doubao-1.8",
      "avatar": ""
    },
    "comments": [],
    "ratings": [],
    "attachments": [
      {
        "id": "zip-arima_time_series_model",
        "originalName": "arima_time_series_model.zip",
        "fileName": "arima_time_series_model.zip",
        "mimeType": "application/zip",
        "size": 8779,
        "path": "/zip/arima_time_series_model.zip"
      }
    ]
  },
  {
    "id": "canonical_correlation_analysis",
    "title": "典型相关分析",
    "description": "典型相关分析（CCA）是一种多元统计方法，用于探究两组变量集合之间的线性相关关系，识别并量化两组变量的潜在关联模式，广泛应用于心理学、经济学、生物学等领域的多变量数据分析。",
    "author": "Doubao-1.8",
    "version": "1.0",
    "trigger": "[\"典型相关分析\", \"CCA\", \"两组变量相关性分析\", \"变量集合关联分析\", \"多变量组间相关性\"]",
    "output_format": "|",
    "content": "---\nname: 典型相关分析\ndescription: 典型相关分析（CCA）是一种多元统计方法，用于探究两组变量集合之间的线性相关关系，识别并量化两组变量的潜在关联模式，广泛应用于心理学、经济学、生物学等领域的多变量数据分析。\nauthor: Doubao-1.8\nversion: 1.0\ntrigger: [\"典型相关分析\", \"CCA\", \"两组变量相关性分析\", \"变量集合关联分析\", \"多变量组间相关性\"]\noutput_format: |\n  1. 典型相关系数（按从大到小排序，反映每对典型变量的关联强度）\n  2. 典型载荷矩阵（原变量与对应典型变量的相关系数，解释原变量对典型变量的贡献）\n  3. 典型权重矩阵（计算典型变量的线性组合系数）\n  4. 典型变量得分（每组变量对应的典型变量取值）\n  5. 显著性检验结果（判断典型相关系数的统计显著性）\n---\n\n## 工作流程\n1. **数据准备**：收集两组连续型数值变量数据，确保无缺失值，样本量需满足n ≥ 5*(p+q)（p为第一组变量数，q为第二组变量数）。\n2. **数据标准化**：对两组变量分别进行标准化处理（均值为0，方差为1），消除量纲差异对分析结果的影响。\n3. **模型拟合**：使用典型相关分析算法拟合数据，计算典型相关系数、载荷、权重等核心指标。\n4. **结果解读**：分析典型相关系数的大小与显著性，通过典型载荷判断原变量与典型变量的关联程度，解释两组变量集合的潜在关联模式。\n5. **可视化（可选）**：绘制典型变量得分散点图，直观展示两组典型变量之间的线性关系。\n\n## 约束条件\n- 变量类型：两组变量必须为连续型数值变量，不支持分类变量或离散变量。\n- 样本量要求：样本数量需远大于两组变量总数，避免模型过拟合或结果不稳定。\n- 多重共线性：每组变量内部应避免严重的多重共线性问题，建议先进行共线性检验（如方差膨胀因子VIF）。\n- 数据完整性：输入数据需无缺失值，若存在缺失值需先进行插值或删除处理。\n\n## 工具使用\n典型相关分析的Python实现位于`scripts/model.py`中，提供了封装好的`CanonicalCorrelationAnalysis`类。使用时只需传入两组变量数据（支持Pandas DataFrame或NumPy数组），调用`fit()`方法完成模型拟合后，可通过类属性获取各类分析结果，或使用`get_results_summary()`方法获取结构化的结果摘要，便于快速解读。",
    "tags": [
      {
        "id": "t1",
        "name": "数学建模"
      }
    ],
    "downloadCount": 0,
    "rating": 5.0,
    "publishDate": "2026-01-30",
    "icon": "Code",
    "color": "blue",
    "status": "approved",
    "user": {
      "id": "id",
      "name": "Doubao-1.8",
      "avatar": ""
    },
    "comments": [],
    "ratings": [],
    "attachments": [
      {
        "id": "zip-canonical_correlation_analysis",
        "originalName": "canonical_correlation_analysis.zip",
        "fileName": "canonical_correlation_analysis.zip",
        "mimeType": "application/zip",
        "size": 8259,
        "path": "/zip/canonical_correlation_analysis.zip"
      }
    ]
  },
  {
    "id": "categorical_independence_test",
    "title": "分类变量独立性检验",
    "description": "用于检验两个分类变量之间是否存在统计独立性的假设检验方法，通过卡方检验实现，可应用于如性别与消费偏好、地区与疾病发病率等场景的相关性分析。",
    "author": "Doubao-1.8",
    "version": "1.0",
    "trigger": "当需要分析两个分类变量是否存在关联时触发，例如判断不同群体的行为特征是否存在差异、分类变量间是否具有统计依赖性等。",
    "output_format": "包含卡方统计量、p值、自由度、期望频数及检验结论的结构化结果（如JSON格式）。",
    "content": "---\nname: 分类变量独立性检验\ndescription: 用于检验两个分类变量之间是否存在统计独立性的假设检验方法，通过卡方检验实现，可应用于如性别与消费偏好、地区与疾病发病率等场景的相关性分析。\nauthor: Doubao-1.8\nversion: 1.0\ntrigger: 当需要分析两个分类变量是否存在关联时触发，例如判断不同群体的行为特征是否存在差异、分类变量间是否具有统计依赖性等。\noutput_format: 包含卡方统计量、p值、自由度、期望频数及检验结论的结构化结果（如JSON格式）。\n---\n\n## 工作流程\n1. **提出假设**：原假设H₀为两个分类变量相互独立；备择假设H₁为两个分类变量不独立（存在关联）。\n2. **构建列联表**：整理两个分类变量的观测频数，形成二维列联表。\n3. **计算期望频数**：每个单元格的期望频数计算公式为：$E_{ij} = \\frac{行合计_i \\times 列合计_j}{总样本量}$。\n4. **计算卡方统计量**：根据观测频数与期望频数的差异计算卡方统计量：$\\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}$，其中$O_{ij}$为观测频数，$E_{ij}$为期望频数。\n5. **确定自由度**：自由度$df = (行数-1) \\times (列数-1)$。\n6. **作出决策**：比较卡方统计量与临界值，或通过p值判断是否拒绝原假设（通常以p<0.05为显著性水平）。\n\n## 约束条件\n1. 样本量需满足列联表中大部分单元格的期望频数不小于5；若存在多个单元格期望频数小于5，建议使用Fisher精确检验等替代方法。\n2. 数据必须为分类变量，且观测值为频数数据。\n3. 所有观测值之间相互独立，无重复测量或配对关系。\n\n## 工具使用\n本方法的Python实现位于`scripts/model.py`，提供了`categorical_independence_test`函数，可直接传入列联表数据（支持二维列表或Pandas DataFrame格式），返回包含检验结果的结构化数据。",
    "tags": [
      {
        "id": "t1",
        "name": "数学建模"
      }
    ],
    "downloadCount": 0,
    "rating": 5.0,
    "publishDate": "2026-01-30",
    "icon": "Code",
    "color": "blue",
    "status": "approved",
    "user": {
      "id": "id",
      "name": "Doubao-1.8",
      "avatar": ""
    },
    "comments": [],
    "ratings": [],
    "attachments": [
      {
        "id": "zip-categorical_independence_test",
        "originalName": "categorical_independence_test.zip",
        "fileName": "categorical_independence_test.zip",
        "mimeType": "application/zip",
        "size": 5568,
        "path": "/zip/categorical_independence_test.zip"
      }
    ]
  },
  {
    "id": "clustering_analysis",
    "title": "聚类分析",
    "description": "一种无监督学习方法，用于将相似的数据点自动分组到不同的簇中，适用于数据探索、客户细分、异常检测等场景。",
    "author": "Doubao-1.8",
    "version": "1.0",
    "trigger": "[\"聚类分析\", \"数据分组\", \"无监督分类\", \"簇划分\"]",
    "output_format": "|",
    "content": "---\nname: 聚类分析\ndescription: 一种无监督学习方法，用于将相似的数据点自动分组到不同的簇中，适用于数据探索、客户细分、异常检测等场景。\nauthor: Doubao-1.8\nversion: 1.0\ntrigger: [\"聚类分析\", \"数据分组\", \"无监督分类\", \"簇划分\"]\noutput_format: |\n  {\n    \"cluster_labels\": [列表，每个样本的簇标签],\n    \"evaluation_metrics\": {\n      \"silhouette_score\": 数值（轮廓系数）,\n      \"calinski_harabasz_score\": 数值（CH指数）（仅适用于基于中心的算法）\n    },\n    \"algorithm_used\": \"使用的聚类算法名称\"\n  }\n---\n\n## 工作流程\n1. **数据预处理**：对输入数据进行缺失值填充、标准化/归一化处理，确保数据质量。\n2. **算法选择**：根据数据特性和业务需求选择合适的聚类算法（如K-Means适用于凸形簇，DBSCAN适用于密度不均匀的簇）。\n3. **参数调优**：通过网格搜索或肘部法则确定最优参数（如K-Means的簇数k，DBSCAN的eps和min_samples）。\n4. **模型训练**：使用预处理后的数据训练聚类模型。\n5. **结果评估**：利用轮廓系数、CH指数等指标评估聚类效果。\n6. **结果输出**：返回每个样本的簇标签及评估指标。\n\n## 约束条件\n- 仅适用于无监督学习场景，输入数据需无标签；\n- K-Means算法对异常值敏感，需先进行异常值检测与处理；\n- DBSCAN算法依赖于eps和min_samples参数的合理设置，对参数较为敏感；\n- 数据维度较高时建议先进行降维处理（如PCA）以提升聚类效果和效率。\n\n## 工具使用\n聚类分析的Python实现位于`scripts/model.py`，提供了`ClusteringAnalyzer`类，支持K-Means和DBSCAN两种常用聚类算法。该类封装了数据预处理、模型训练、结果评估及可视化等功能，可通过简单调用完成完整的聚类分析任务。",
    "tags": [
      {
        "id": "t1",
        "name": "数学建模"
      }
    ],
    "downloadCount": 0,
    "rating": 5.0,
    "publishDate": "2026-01-30",
    "icon": "Code",
    "color": "blue",
    "status": "approved",
    "user": {
      "id": "id",
      "name": "Doubao-1.8",
      "avatar": ""
    },
    "comments": [],
    "ratings": [],
    "attachments": [
      {
        "id": "zip-clustering_analysis",
        "originalName": "clustering_analysis.zip",
        "fileName": "clustering_analysis.zip",
        "mimeType": "application/zip",
        "size": 7289,
        "path": "/zip/clustering_analysis.zip"
      }
    ]
  },
  {
    "id": "discriminant_analysis",
    "title": "判别分析",
    "description": "判别分析是一种经典的统计分类方法，通过构建判别函数将样本划分为预先定义的类别。它通过分析不同类别样本的特征差异，找到最优的分类边界，适用于监督学习场景下的分类任务，如客户分群、疾病诊断、信用评级等。",
    "author": "Doubao-1.8",
    "version": "1.0",
    "trigger": "[\"判别分析\", \"样本分类\", \"分类预测\", \"类别判别\", \"LDA\", \"QDA\"]",
    "output_format": "|",
    "content": "---\nname: 判别分析\ndescription: 判别分析是一种经典的统计分类方法，通过构建判别函数将样本划分为预先定义的类别。它通过分析不同类别样本的特征差异，找到最优的分类边界，适用于监督学习场景下的分类任务，如客户分群、疾病诊断、信用评级等。\nauthor: Doubao-1.8\nversion: 1.0\ntrigger: [\"判别分析\", \"样本分类\", \"分类预测\", \"类别判别\", \"LDA\", \"QDA\"]\noutput_format: |\n  {\n    \"model_type\": \"string, 模型类型（如LDA/QDA）\",\n    \"predicted_labels\": \"list, 样本的预测类别\",\n    \"accuracy\": \"float, 模型分类准确率（若提供测试集）\",\n    \"discriminant_params\": \"dict, 判别函数的关键参数（如LDA的系数、截距，QDA的协方差矩阵）\"\n  }\n---\n\n## 工作流程\n1. **数据准备**：收集带有类别标签的样本数据，划分训练集与测试集；对数值型特征进行标准化处理，对分类特征进行编码（如独热编码），确保数据符合模型假设（如LDA要求的正态分布、方差齐性）。\n2. **模型选择**：根据数据特征选择合适的判别模型：\n   - 线性判别分析（LDA）：适用于类别间协方差矩阵相近的场景，分类边界为线性。\n   - 二次判别分析（QDA）：适用于类别间协方差矩阵差异较大的场景，分类边界为二次曲线。\n3. **模型训练**：使用训练集拟合判别模型，学习类别间的判别规则。\n4. **预测与评估**：对测试集样本进行分类预测，使用准确率、混淆矩阵、F1值等指标评估模型性能。\n5. **结果解释**：分析判别函数的参数（如特征系数），理解各特征对分类结果的贡献程度。\n\n## 约束条件\n1. **数据假设**：\n   - LDA要求各类别样本的特征服从多元正态分布，且协方差矩阵相等；\n   - QDA放松了协方差矩阵相等的假设，但仍要求特征服从多元正态分布。\n2. **样本量**：每个类别的样本数量应大于特征维度，避免模型过拟合；类别间样本量尽量均衡，否则需调整先验概率。\n3. **特征类型**：仅支持数值型特征，分类特征需提前转换为数值形式。\n4. **适用场景**：适用于监督分类任务，需有带标签的训练数据。\n\n## 工具使用\n本技能的实现代码位于`scripts/model.py`，提供了封装好的`DiscriminantAnalysis`类，支持LDA和QDA两种模型。使用步骤如下：\n1. 导入`DiscriminantAnalysis`类；\n2. 初始化模型并指定类型（LDA/QDA）；\n3. 调用`fit()`方法传入训练数据完成模型训练；\n4. 调用`predict()`方法对新样本进行分类；\n5. 调用`evaluate()`方法评估模型性能；\n6. 调用`get_discriminant_params()`方法获取判别函数的关键参数用于结果解释。",
    "tags": [
      {
        "id": "t1",
        "name": "数学建模"
      }
    ],
    "downloadCount": 0,
    "rating": 5.0,
    "publishDate": "2026-01-30",
    "icon": "Code",
    "color": "blue",
    "status": "approved",
    "user": {
      "id": "id",
      "name": "Doubao-1.8",
      "avatar": ""
    },
    "comments": [],
    "ratings": [],
    "attachments": [
      {
        "id": "zip-discriminant_analysis",
        "originalName": "discriminant_analysis.zip",
        "fileName": "discriminant_analysis.zip",
        "mimeType": "application/zip",
        "size": 7953,
        "path": "/zip/discriminant_analysis.zip"
      }
    ]
  }
]