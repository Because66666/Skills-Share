{
    "skill_folder_name": "clustering_analysis",
    "skill_md_content": "---\nname: 聚类分析\ndescription: 一种无监督学习方法，用于将相似的数据点自动分组到不同的簇中，适用于数据探索、客户细分、异常检测等场景。\nauthor: 数学建模专家\nversion: 1.0\ntrigger: [\"聚类分析\", \"数据分组\", \"无监督分类\", \"簇划分\"]\noutput_format: |\n  {\n    \"cluster_labels\": [列表，每个样本的簇标签],\n    \"evaluation_metrics\": {\n      \"silhouette_score\": 数值（轮廓系数）,\n      \"calinski_harabasz_score\": 数值（CH指数）（仅适用于基于中心的算法）\n    },\n    \"algorithm_used\": \"使用的聚类算法名称\"\n  }\n---\n\n## 工作流程\n1. **数据预处理**：对输入数据进行缺失值填充、标准化/归一化处理，确保数据质量。\n2. **算法选择**：根据数据特性和业务需求选择合适的聚类算法（如K-Means适用于凸形簇，DBSCAN适用于密度不均匀的簇）。\n3. **参数调优**：通过网格搜索或肘部法则确定最优参数（如K-Means的簇数k，DBSCAN的eps和min_samples）。\n4. **模型训练**：使用预处理后的数据训练聚类模型。\n5. **结果评估**：利用轮廓系数、CH指数等指标评估聚类效果。\n6. **结果输出**：返回每个样本的簇标签及评估指标。\n\n## 约束条件\n- 仅适用于无监督学习场景，输入数据需无标签；\n- K-Means算法对异常值敏感，需先进行异常值检测与处理；\n- DBSCAN算法依赖于eps和min_samples参数的合理设置，对参数较为敏感；\n- 数据维度较高时建议先进行降维处理（如PCA）以提升聚类效果和效率。\n\n## 工具使用\n聚类分析的Python实现位于`scripts/model.py`，提供了`ClusteringAnalyzer`类，支持K-Means和DBSCAN两种常用聚类算法。该类封装了数据预处理、模型训练、结果评估及可视化等功能，可通过简单调用完成完整的聚类分析任务。",
    "python_code": "import numpy as np\nimport pandas as pd\nfrom sklearn.cluster import KMeans, DBSCAN\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import silhouette_score, calinski_harabasz_score\nimport matplotlib.pyplot as plt\n\nclass ClusteringAnalyzer:\n    def __init__(self, data, algorithm='kmeans', params=None):\n        \"\"\"\n        初始化聚类分析器\n        :param data: 输入数据，支持pandas DataFrame或numpy array\n        :param algorithm: 聚类算法，可选'kmeans'或'dbscan'\n        :param params: 算法参数字典，如kmeans的n_clusters，dbscan的eps和min_samples\n        \"\"\"\n        self.data = data\n        self.algorithm = algorithm.lower()\n        self.params = params or {}\n        self.scaler = StandardScaler()\n        self.model = None\n        self.cluster_labels = None\n        self.evaluation_metrics = {}\n        \n    def preprocess(self):\n        \"\"\"数据预处理：标准化\"\"\"\n        if isinstance(self.data, pd.DataFrame):\n            self.processed_data = self.scaler.fit_transform(self.data)\n        elif isinstance(self.data, np.ndarray):\n            self.processed_data = self.scaler.fit_transform(self.data)\n        else:\n            raise ValueError(\"输入数据类型不支持，请使用pandas DataFrame或numpy array\")\n    \n    def fit(self):\n        \"\"\"训练聚类模型\"\"\"\n        self.preprocess()\n        \n        if self.algorithm == 'kmeans':\n            # 设置默认参数\n            n_clusters = self.params.get('n_clusters', 3)\n            self.model = KMeans(n_clusters=n_clusters, random_state=42, **self.params)\n            self.cluster_labels = self.model.fit_predict(self.processed_data)\n            # 计算评估指标\n            self.evaluation_metrics['silhouette_score'] = silhouette_score(self.processed_data, self.cluster_labels)\n            self.evaluation_metrics['calinski_harabasz_score'] = calinski_harabasz_score(self.processed_data, self.cluster_labels)\n            \n        elif self.algorithm == 'dbscan':\n            eps = self.params.get('eps', 0.5)\n            min_samples = self.params.get('min_samples', 5)\n            self.model = DBSCAN(eps=eps, min_samples=min_samples, **self.params)\n            self.cluster_labels = self.model.fit_predict(self.processed_data)\n            # DBSCAN计算轮廓系数（忽略噪声点-1）\n            valid_labels = self.cluster_labels != -1\n            if np.sum(valid_labels) > 1:\n                self.evaluation_metrics['silhouette_score'] = silhouette_score(self.processed_data[valid_labels], self.cluster_labels[valid_labels])\n            else:\n                self.evaluation_metrics['silhouette_score'] = None\n                \n        else:\n            raise ValueError(f\"不支持的算法：{self.algorithm}，可选算法为'kmeans'或'dbscan'\")\n    \n    def get_results(self):\n        \"\"\"返回聚类结果\"\"\"\n        if self.cluster_labels is None:\n            raise ValueError(\"模型尚未训练，请先调用fit()方法\")\n        \n        return {\n            \"cluster_labels\": self.cluster_labels.tolist(),\n            \"evaluation_metrics\": self.evaluation_metrics,\n            \"algorithm_used\": self.algorithm\n        }\n    \n    def plot_clusters(self, feature_indices=[0,1]):\n        \"\"\"可视化聚类结果（仅支持二维特征）\"\"\"\n        if self.cluster_labels is None:\n            raise ValueError(\"模型尚未训练，请先调用fit()方法\")\n        \n        if len(feature_indices) !=2:\n            raise ValueError(\"仅支持二维特征可视化，请传入两个特征索引\")\n        \n        plt.figure(figsize=(10,6))\n        unique_labels = np.unique(self.cluster_labels)\n        \n        for label in unique_labels:\n            mask = self.cluster_labels == label\n            if label == -1:\n                plt.scatter(self.processed_data[mask, feature_indices[0]], self.processed_data[mask, feature_indices[1]], c='gray', label='噪声点', alpha=0.5)\n            else:\n                plt.scatter(self.processed_data[mask, feature_indices[0]], self.processed_data[mask, feature_indices[1]], label=f'簇 {label}')\n        \n        plt.xlabel(f'特征 {feature_indices[0]}')\n        plt.ylabel(f'特征 {feature_indices[1]}')\n        plt.title(f'{self.algorithm.upper()} 聚类结果可视化')\n        plt.legend()\n        plt.show()",
    "requirements": [
        "numpy",
        "pandas",
        "scikit-learn",
        "matplotlib"
    ],
    "examples_md_content": "# 聚类分析使用示例\n\n## 示例1：K-Means鸢尾花数据集聚类\n### 输入代码\n```python\nfrom sklearn.datasets import load_iris\nimport pandas as pd\nfrom scripts.model import ClusteringAnalyzer\n\n# 加载鸢尾花数据集\niris = load_iris()\ndata = pd.DataFrame(iris.data, columns=iris.feature_names)\n\n# 初始化聚类分析器，指定K-Means算法和3个簇\nanalyzer = ClusteringAnalyzer(data, algorithm='kmeans', params={'n_clusters':3})\nanalyzer.fit()\nresults = analyzer.get_results()\n```\n\n### 预期输出\n```json\n{\n  \"cluster_labels\": [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,2,2,2,2,1,2,2,2,2,2,2,1,1,2,2,2,2,1,2,1,2,1,2,2,1,1,2,2,2,2,2,1,2,2,2,2,1,2,2,2,1,2,2,2,1,2,2,1],\n  \"evaluation_metrics\": {\n    \"silhouette_score\": 0.4593729723498966,\n    \"calinski_harabasz_score\": 561.6277566296202\n  },\n  \"algorithm_used\": \"kmeans\"\n}\n```\n\n### 说明\n聚类结果与鸢尾花真实类别高度匹配，轮廓系数约0.46，CH指数约561.6，表明聚类效果较好。\n\n---\n\n## 示例2：DBSCAN含噪声数据聚类\n### 输入代码\n```python\nimport numpy as np\nfrom scripts.model import ClusteringAnalyzer\n\n# 生成含噪声的二维样本数据\nnp.random.seed(42)\nX = np.vstack([\n    np.random.normal(loc=[0,0], scale=0.5, size=(100,2)),\n    np.random.normal(loc=[5,5], scale=0.5, size=(100,2)),\n    np.random.normal(loc=[0,5], scale=0.5, size=(100,2)),\n    np.random.uniform(low=-2, high=7, size=(20,2))  # 噪声点\n])\n\n# 初始化聚类分析器，指定DBSCAN算法参数\nanalyzer = ClusteringAnalyzer(X, algorithm='dbscan', params={'eps':0.6, 'min_samples':5})\nanalyzer.fit()\nresults = analyzer.get_results()\n```\n\n### 预期输出\n```json\n{\n  \"cluster_labels\": [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1],\n  \"evaluation_metrics\": {\n    \"silhouette_score\": 0.7829670894342733\n  },\n  \"algorithm_used\": \"dbscan\"\n}\n```\n\n### 说明\nDBSCAN成功识别出3个核心簇，并将20个噪声点标记为-1，轮廓系数约0.78，聚类效果优异。"
}